{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "whole-place",
   "metadata": {
    "papermill": {
     "duration": 0.026269,
     "end_time": "2021-06-20T10:34:45.306538",
     "exception": false,
     "start_time": "2021-06-20T10:34:45.280269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-edition",
   "metadata": {
    "papermill": {
     "duration": 0.030117,
     "end_time": "2021-06-20T10:34:45.361886",
     "exception": false,
     "start_time": "2021-06-20T10:34:45.331769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "brave-ideal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:45.417852Z",
     "iopub.status.busy": "2021-06-20T10:34:45.416041Z",
     "iopub.status.idle": "2021-06-20T10:34:52.040249Z",
     "shell.execute_reply": "2021-06-20T10:34:52.040762Z"
    },
    "papermill": {
     "duration": 6.653263,
     "end_time": "2021-06-20T10:34:52.041048",
     "exception": false,
     "start_time": "2021-06-20T10:34:45.387785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599995          4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996          4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997          4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998          4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999          4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as nlp\n",
    "tweets=pd.read_csv('./data.csv',encoding='latin', \n",
    "                   names = ['sentiment','id','date','query','user','tweet'])\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "isolated-bicycle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:52.096731Z",
     "iopub.status.busy": "2021-06-20T10:34:52.096045Z",
     "iopub.status.idle": "2021-06-20T10:34:53.410787Z",
     "shell.execute_reply": "2021-06-20T10:34:53.411263Z"
    },
    "papermill": {
     "duration": 1.345454,
     "end_time": "2021-06-20T10:34:53.411479",
     "exception": false,
     "start_time": "2021-06-20T10:34:52.066025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (200000, 6)\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.sample(frac=1)\n",
    "tweets = tweets[:200000]\n",
    "print(\"Dataset shape:\", tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "assisted-fields",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:53.470740Z",
     "iopub.status.busy": "2021-06-20T10:34:53.469709Z",
     "iopub.status.idle": "2021-06-20T10:34:53.476391Z",
     "shell.execute_reply": "2021-06-20T10:34:53.475734Z"
    },
    "papermill": {
     "duration": 0.039405,
     "end_time": "2021-06-20T10:34:53.476544",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.437139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-papua",
   "metadata": {
    "papermill": {
     "duration": 0.024806,
     "end_time": "2021-06-20T10:34:53.526885",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.502079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1 : Currently (0=negative,4=Positive) changing the notation to (0=Negative,1=Positive) \n",
    "### So that we can understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reflected-chamber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:53.583990Z",
     "iopub.status.busy": "2021-06-20T10:34:53.583244Z",
     "iopub.status.idle": "2021-06-20T10:34:53.601198Z",
     "shell.execute_reply": "2021-06-20T10:34:53.600618Z"
    },
    "papermill": {
     "duration": 0.049098,
     "end_time": "2021-06-20T10:34:53.601335",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.552237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>0</td>\n",
       "      <td>1557982468</td>\n",
       "      <td>Sun Apr 19 06:49:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Gracemile</td>\n",
       "      <td>I'm thinking that the world is soooo unfair......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545098</th>\n",
       "      <td>0</td>\n",
       "      <td>2201322355</td>\n",
       "      <td>Tue Jun 16 20:06:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>wozkat</td>\n",
       "      <td>oh tasty twist.. you tasted soo good. but i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425195</th>\n",
       "      <td>0</td>\n",
       "      <td>2063274386</td>\n",
       "      <td>Sun Jun 07 02:00:42 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dstarpro</td>\n",
       "      <td>@neilfairmont And of course I had to miss it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267494</th>\n",
       "      <td>0</td>\n",
       "      <td>1989207932</td>\n",
       "      <td>Mon Jun 01 00:43:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Gemma__M</td>\n",
       "      <td>weekend is now over  have bad sunburn on my ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168949</th>\n",
       "      <td>1</td>\n",
       "      <td>1980202699</td>\n",
       "      <td>Sun May 31 06:01:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>itsprincessS</td>\n",
       "      <td>i reeaally need to get out of town... how abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187330</th>\n",
       "      <td>1</td>\n",
       "      <td>1983137640</td>\n",
       "      <td>Sun May 31 12:34:35 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>levimcconnell</td>\n",
       "      <td>@EasyDrinkRecipe I'll swear by it - Orzel Vodk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723556</th>\n",
       "      <td>0</td>\n",
       "      <td>2261819275</td>\n",
       "      <td>Sat Jun 20 21:24:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>nanabitencourt</td>\n",
       "      <td>sorry for not tweeting today my internet got c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96890</th>\n",
       "      <td>0</td>\n",
       "      <td>1792770010</td>\n",
       "      <td>Thu May 14 00:11:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChrisEmanuel</td>\n",
       "      <td>@matthewrmoore @mcaroleo I doubt he will, it's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488832</th>\n",
       "      <td>1</td>\n",
       "      <td>2068573460</td>\n",
       "      <td>Sun Jun 07 14:18:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Bosslady82504</td>\n",
       "      <td>@SongzYuuup Trey u know ur about to get a mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484428</th>\n",
       "      <td>0</td>\n",
       "      <td>2180772101</td>\n",
       "      <td>Mon Jun 15 10:55:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thePOSHpreneur</td>\n",
       "      <td>@magnoliapr OH I had the mini leaf necklace an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "24389            0  1557982468  Sun Apr 19 06:49:40 PDT 2009  NO_QUERY   \n",
       "545098           0  2201322355  Tue Jun 16 20:06:51 PDT 2009  NO_QUERY   \n",
       "425195           0  2063274386  Sun Jun 07 02:00:42 PDT 2009  NO_QUERY   \n",
       "267494           0  1989207932  Mon Jun 01 00:43:00 PDT 2009  NO_QUERY   \n",
       "1168949          1  1980202699  Sun May 31 06:01:49 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1187330          1  1983137640  Sun May 31 12:34:35 PDT 2009  NO_QUERY   \n",
       "723556           0  2261819275  Sat Jun 20 21:24:11 PDT 2009  NO_QUERY   \n",
       "96890            0  1792770010  Thu May 14 00:11:08 PDT 2009  NO_QUERY   \n",
       "1488832          1  2068573460  Sun Jun 07 14:18:58 PDT 2009  NO_QUERY   \n",
       "484428           0  2180772101  Mon Jun 15 10:55:27 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                              tweet  \n",
       "24389         Gracemile  I'm thinking that the world is soooo unfair......  \n",
       "545098           wozkat  oh tasty twist.. you tasted soo good. but i do...  \n",
       "425195         dstarpro      @neilfairmont And of course I had to miss it   \n",
       "267494         Gemma__M  weekend is now over  have bad sunburn on my ar...  \n",
       "1168949    itsprincessS  i reeaally need to get out of town... how abou...  \n",
       "...                 ...                                                ...  \n",
       "1187330   levimcconnell  @EasyDrinkRecipe I'll swear by it - Orzel Vodk...  \n",
       "723556   nanabitencourt  sorry for not tweeting today my internet got c...  \n",
       "96890      ChrisEmanuel  @matthewrmoore @mcaroleo I doubt he will, it's...  \n",
       "1488832   Bosslady82504  @SongzYuuup Trey u know ur about to get a mill...  \n",
       "484428   thePOSHpreneur  @magnoliapr OH I had the mini leaf necklace an...  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment']=tweets['sentiment'].replace(4,1)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-footwear",
   "metadata": {
    "papermill": {
     "duration": 0.026491,
     "end_time": "2021-06-20T10:34:53.654225",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.627734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "vertical-tunisia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:53.834454Z",
     "iopub.status.busy": "2021-06-20T10:34:53.713669Z",
     "iopub.status.idle": "2021-06-20T10:34:53.861543Z",
     "shell.execute_reply": "2021-06-20T10:34:53.860995Z"
    },
    "papermill": {
     "duration": 0.180739,
     "end_time": "2021-06-20T10:34:53.861695",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.680956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm thinking that the world is soooo unfair......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545098</th>\n",
       "      <td>0</td>\n",
       "      <td>oh tasty twist.. you tasted soo good. but i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425195</th>\n",
       "      <td>0</td>\n",
       "      <td>@neilfairmont And of course I had to miss it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267494</th>\n",
       "      <td>0</td>\n",
       "      <td>weekend is now over  have bad sunburn on my ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168949</th>\n",
       "      <td>1</td>\n",
       "      <td>i reeaally need to get out of town... how abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728149</th>\n",
       "      <td>0</td>\n",
       "      <td>All the easy cleaning things done. Down to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578019</th>\n",
       "      <td>0</td>\n",
       "      <td>@natalieridout Angel still. It's one I saw bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186884</th>\n",
       "      <td>1</td>\n",
       "      <td>@LauraWhittaker yep  are you here {;o)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405452</th>\n",
       "      <td>1</td>\n",
       "      <td>@Work they doing mad construction right now.I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295847</th>\n",
       "      <td>1</td>\n",
       "      <td>@plainlyphyra i only search though the urban d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "24389            0  I'm thinking that the world is soooo unfair......\n",
       "545098           0  oh tasty twist.. you tasted soo good. but i do...\n",
       "425195           0      @neilfairmont And of course I had to miss it \n",
       "267494           0  weekend is now over  have bad sunburn on my ar...\n",
       "1168949          1  i reeaally need to get out of town... how abou...\n",
       "728149           0  All the easy cleaning things done. Down to the...\n",
       "578019           0  @natalieridout Angel still. It's one I saw bef...\n",
       "1186884          1             @LauraWhittaker yep  are you here {;o)\n",
       "1405452          1  @Work they doing mad construction right now.I'...\n",
       "1295847          1  @plainlyphyra i only search though the urban d..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop(['date','query','user'], axis=1, inplace=True)\n",
    "tweets.drop('id', axis=1, inplace=True)\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-mauritius",
   "metadata": {
    "papermill": {
     "duration": 0.026876,
     "end_time": "2021-06-20T10:34:53.915403",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.888527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking if any null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sharp-sound",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:54.009641Z",
     "iopub.status.busy": "2021-06-20T10:34:54.008959Z",
     "iopub.status.idle": "2021-06-20T10:34:54.029701Z",
     "shell.execute_reply": "2021-06-20T10:34:54.030165Z"
    },
    "papermill": {
     "duration": 0.087779,
     "end_time": "2021-06-20T10:34:54.030344",
     "exception": false,
     "start_time": "2021-06-20T10:34:53.942565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0.0\n",
       "tweet        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tweets.isnull().sum() / len(tweets))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "catholic-movement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:54.089297Z",
     "iopub.status.busy": "2021-06-20T10:34:54.088718Z",
     "iopub.status.idle": "2021-06-20T10:34:54.137601Z",
     "shell.execute_reply": "2021-06-20T10:34:54.138066Z"
    },
    "papermill": {
     "duration": 0.080202,
     "end_time": "2021-06-20T10:34:54.138248",
     "exception": false,
     "start_time": "2021-06-20T10:34:54.058046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#converting pandas object to a string type\n",
    "tweets['tweet'] = tweets['tweet'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-separation",
   "metadata": {
    "papermill": {
     "duration": 0.02759,
     "end_time": "2021-06-20T10:34:54.193182",
     "exception": false,
     "start_time": "2021-06-20T10:34:54.165592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check the number of positive vs. negative tagged sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "straight-boards",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:54.253191Z",
     "iopub.status.busy": "2021-06-20T10:34:54.252505Z",
     "iopub.status.idle": "2021-06-20T10:34:54.270606Z",
     "shell.execute_reply": "2021-06-20T10:34:54.270091Z"
    },
    "papermill": {
     "duration": 0.048133,
     "end_time": "2021-06-20T10:34:54.270744",
     "exception": false,
     "start_time": "2021-06-20T10:34:54.222611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of the data is:         200000\n",
      "No. of positve tagged sentences is:  99837\n",
      "No. of negative tagged sentences is: 100163\n"
     ]
    }
   ],
   "source": [
    "positives = tweets['sentiment'][tweets.sentiment == 1 ]\n",
    "negatives = tweets['sentiment'][tweets.sentiment == 0 ]\n",
    "\n",
    "print('Total length of the data is:         {}'.format(tweets.shape[0]))\n",
    "print('No. of positve tagged sentences is:  {}'.format(len(positives)))\n",
    "print('No. of negative tagged sentences is: {}'.format(len(negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "complicated-necklace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:54.332860Z",
     "iopub.status.busy": "2021-06-20T10:34:54.332017Z",
     "iopub.status.idle": "2021-06-20T10:34:55.867092Z",
     "shell.execute_reply": "2021-06-20T10:34:55.868087Z"
    },
    "papermill": {
     "duration": 1.569549,
     "end_time": "2021-06-20T10:34:55.868405",
     "exception": false,
     "start_time": "2021-06-20T10:34:54.298856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'myself', 'above', 'be', 'who', \"wasn't\", 'herself', 'same', 'do', 'is', 'should', 'all', 'after', 'my', 'very', 'll', 'mightn', 'were', 'again', 'they', 'few', 'at', 'didn', 'now', 'own', 'below', 'y', \"you'd\", 'yourself', 'shan', 'me', 'while', 'these', \"weren't\", 'about', 'has', 'each', 'its', 'how', 'once', 'through', 'your', 're', \"didn't\", 'doesn', 'him', 'any', 't', 'before', 'd', 'haven', \"shan't\", 'wasn', 'yourselves', 'nor', \"you've\", 'such', 'some', 'hers', 'to', 'or', 'most', \"mightn't\", 'but', 'until', 'as', 'more', 'ma', 'down', \"couldn't\", 'hasn', 'in', 'theirs', 'ours', 'had', 'into', \"mustn't\", 'under', 'which', 'weren', 'shouldn', 'where', 'her', 'their', 'won', 'of', 'both', 'an', 'having', 'too', 'not', 'ourselves', 'we', 'over', 'because', 'aren', 'ain', 's', 'he', 'our', 'itself', 'the', \"hadn't\", 'there', 'needn', 'on', 'so', 'o', \"it's\", 'i', 'wouldn', 'what', 'it', 'this', \"hasn't\", 'from', 'are', 'am', 'why', 'up', 'against', 'further', 'isn', 'during', 'other', 'when', \"isn't\", \"that'll\", 'that', 'did', 've', 'hadn', 'those', 'himself', 'been', 'between', \"haven't\", 'can', \"doesn't\", 'm', 'than', \"you'll\", 'a', \"don't\", 'just', 'yours', 'themselves', 'was', 'with', 'and', \"shouldn't\", 'out', \"won't\", 'his', \"she's\", 'does', 'mustn', 'them', 'you', 'doing', \"wouldn't\", 'here', 'for', 'no', \"should've\", \"you're\", 'she', 'whom', 'have', 'don', \"aren't\", 'off', 'by', 'only', 'if', \"needn't\", 'couldn', 'being', 'then', 'will'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ibtehaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ibtehaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ibtehaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Ibtehaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) \n",
    "#that a search engine has been programmed to ignore,\n",
    "#both when indexing entries for searching and when retrieving them as the result of a search query.\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stopword = set(stopwords.words('english'))\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-merchant",
   "metadata": {
    "papermill": {
     "duration": 0.028002,
     "end_time": "2021-06-20T10:34:55.926164",
     "exception": false,
     "start_time": "2021-06-20T10:34:55.898162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "identical-membership",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:55.987781Z",
     "iopub.status.busy": "2021-06-20T10:34:55.986488Z",
     "iopub.status.idle": "2021-06-20T10:34:56.132827Z",
     "shell.execute_reply": "2021-06-20T10:34:56.132015Z"
    },
    "papermill": {
     "duration": 0.178121,
     "end_time": "2021-06-20T10:34:56.133003",
     "exception": false,
     "start_time": "2021-06-20T10:34:55.954882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "userPattern = '@[^\\s]+'\n",
    "some = 'amp,today,tomorrow,going,girl'\n",
    "def process_tweets(tweet):\n",
    "  # Lower Casing\n",
    "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
    "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
    "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
    "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
    "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
    "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
    "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
    "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
    "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
    "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
    "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
    "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
    "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
    "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
    "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
    "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
    "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
    "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
    "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
    "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
    "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
    "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
    "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
    "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
    "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
    "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
    "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
    "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
    "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
    "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
    "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
    "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
    "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
    "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
    "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
    "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
    "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
    "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
    "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
    "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)  \n",
    "    \n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = re.sub(r\"yrs\", \"years\", tweet)\n",
    "    tweet = re.sub(r\"hrs\", \"hours\", tweet)\n",
    "    tweet = re.sub(r\"2morow|2moro\", \"tomorrow\", tweet)\n",
    "    tweet = re.sub(r\"2day\", \"today\", tweet)\n",
    "    tweet = re.sub(r\"4got|4gotten\", \"forget\", tweet)\n",
    "    tweet = re.sub(r\"b-day|bday\", \"b-day\", tweet)\n",
    "    tweet = re.sub(r\"mother's\", \"mother\", tweet)\n",
    "    tweet = re.sub(r\"mom's\", \"mom\", tweet)\n",
    "    tweet = re.sub(r\"dad's\", \"dad\", tweet)\n",
    "    tweet = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", tweet)\n",
    "    tweet = re.sub(r\"lmao|lolz|rofl\", \"lol\", tweet)\n",
    "    tweet = re.sub(r\"thanx|thnx\", \"thanks\", tweet)\n",
    "    tweet = re.sub(r\"goood\", \"good\", tweet)\n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet=tweet[1:]\n",
    "    # Removing all URls \n",
    "    tweet = re.sub(urlPattern,'',tweet)\n",
    "    # Removing all @username.\n",
    "    tweet = re.sub(userPattern,'', tweet) \n",
    "    #remove some words\n",
    "    tweet= re.sub(some,'',tweet)\n",
    "    #Remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    #tokenizing words\n",
    "    tokens = word_tokenize(tweet)\n",
    "    #tokens = [w for w in tokens if len(w)>2]\n",
    "    #Removing Stop Words\n",
    "    final_tokens = [w for w in tokens if w not in stopword]\n",
    "    #reducing a word to its word stem \n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    finalwords=[]\n",
    "    for w in final_tokens:\n",
    "      if len(w)>1:\n",
    "        word = wordLemm.lemmatize(w)\n",
    "        finalwords.append(word)\n",
    "    return ' '.join(finalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acceptable-grain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:56.195511Z",
     "iopub.status.busy": "2021-06-20T10:34:56.194074Z",
     "iopub.status.idle": "2021-06-20T10:34:56.219608Z",
     "shell.execute_reply": "2021-06-20T10:34:56.220078Z"
    },
    "papermill": {
     "duration": 0.058325,
     "end_time": "2021-06-20T10:34:56.220258",
     "exception": false,
     "start_time": "2021-06-20T10:34:56.161933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", \n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "     \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "foreign-huntington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:56.281134Z",
     "iopub.status.busy": "2021-06-20T10:34:56.280516Z",
     "iopub.status.idle": "2021-06-20T10:34:56.284857Z",
     "shell.execute_reply": "2021-06-20T10:34:56.285368Z"
    },
    "papermill": {
     "duration": 0.036537,
     "end_time": "2021-06-20T10:34:56.285546",
     "exception": false,
     "start_time": "2021-06-20T10:34:56.249009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_abbrev_in_text(tweet):\n",
    "    t=[]\n",
    "    words=tweet.split()\n",
    "    t = [abbreviations[w.lower()] if w.lower() in abbreviations.keys() else w for w in words]\n",
    "    return ' '.join(t)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-schema",
   "metadata": {
    "papermill": {
     "duration": 0.028246,
     "end_time": "2021-06-20T10:34:56.342344",
     "exception": false,
     "start_time": "2021-06-20T10:34:56.314098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Text Processing Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "convenient-corpus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:34:56.402445Z",
     "iopub.status.busy": "2021-06-20T10:34:56.401788Z",
     "iopub.status.idle": "2021-06-20T10:36:15.698989Z",
     "shell.execute_reply": "2021-06-20T10:36:15.698440Z"
    },
    "papermill": {
     "duration": 79.328345,
     "end_time": "2021-06-20T10:36:15.699122",
     "exception": false,
     "start_time": "2021-06-20T10:34:56.370777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm thinking that the world is soooo unfair......</td>\n",
       "      <td>thinking world soooo unfair sure think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545098</th>\n",
       "      <td>0</td>\n",
       "      <td>oh tasty twist.. you tasted soo good. but i do...</td>\n",
       "      <td>tasty twist tasted soo good appreciate stomach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425195</th>\n",
       "      <td>0</td>\n",
       "      <td>@neilfairmont And of course I had to miss it</td>\n",
       "      <td>neilfairmont course miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267494</th>\n",
       "      <td>0</td>\n",
       "      <td>weekend is now over  have bad sunburn on my ar...</td>\n",
       "      <td>eekend bad sunburn arm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168949</th>\n",
       "      <td>1</td>\n",
       "      <td>i reeaally need to get out of town... how abou...</td>\n",
       "      <td>reeaally need get town paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187330</th>\n",
       "      <td>1</td>\n",
       "      <td>@EasyDrinkRecipe I'll swear by it - Orzel Vodk...</td>\n",
       "      <td>easydrinkrecipe swear orzel vodka better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723556</th>\n",
       "      <td>0</td>\n",
       "      <td>sorry for not tweeting today my internet got c...</td>\n",
       "      <td>orry tweeting today internet got crazy tweet t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96890</th>\n",
       "      <td>0</td>\n",
       "      <td>@matthewrmoore @mcaroleo I doubt he will, it's...</td>\n",
       "      <td>matthewrmoore doubt late catch morning maybe t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488832</th>\n",
       "      <td>1</td>\n",
       "      <td>@SongzYuuup Trey u know ur about to get a mill...</td>\n",
       "      <td>songzyuuup trey know ur get million ill baby r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484428</th>\n",
       "      <td>0</td>\n",
       "      <td>@magnoliapr OH I had the mini leaf necklace an...</td>\n",
       "      <td>magnoliapr oh mini leaf necklace lost chain br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet  \\\n",
       "24389            0  I'm thinking that the world is soooo unfair......   \n",
       "545098           0  oh tasty twist.. you tasted soo good. but i do...   \n",
       "425195           0      @neilfairmont And of course I had to miss it    \n",
       "267494           0  weekend is now over  have bad sunburn on my ar...   \n",
       "1168949          1  i reeaally need to get out of town... how abou...   \n",
       "...            ...                                                ...   \n",
       "1187330          1  @EasyDrinkRecipe I'll swear by it - Orzel Vodk...   \n",
       "723556           0  sorry for not tweeting today my internet got c...   \n",
       "96890            0  @matthewrmoore @mcaroleo I doubt he will, it's...   \n",
       "1488832          1  @SongzYuuup Trey u know ur about to get a mill...   \n",
       "484428           0  @magnoliapr OH I had the mini leaf necklace an...   \n",
       "\n",
       "                                          processed_tweets  \n",
       "24389               thinking world soooo unfair sure think  \n",
       "545098   tasty twist tasted soo good appreciate stomach...  \n",
       "425195                            neilfairmont course miss  \n",
       "267494                              eekend bad sunburn arm  \n",
       "1168949                       reeaally need get town paris  \n",
       "...                                                    ...  \n",
       "1187330           easydrinkrecipe swear orzel vodka better  \n",
       "723556   orry tweeting today internet got crazy tweet t...  \n",
       "96890    matthewrmoore doubt late catch morning maybe t...  \n",
       "1488832  songzyuuup trey know ur get million ill baby r...  \n",
       "484428   magnoliapr oh mini leaf necklace lost chain br...  \n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['processed_tweets'] = tweets['tweet'].apply(lambda x: process_tweets(x))\n",
    "tweets['processed_tweets'] = tweets['processed_tweets'].apply(lambda x: convert_abbrev_in_text(x))\n",
    "print('Text Preprocessing complete.')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "designing-rwanda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T10:36:15.763567Z",
     "iopub.status.busy": "2021-06-20T10:36:15.762933Z",
     "iopub.status.idle": "2021-06-20T10:36:16.218687Z",
     "shell.execute_reply": "2021-06-20T10:36:16.218199Z"
    },
    "papermill": {
     "duration": 0.490404,
     "end_time": "2021-06-20T10:36:16.218821",
     "exception": false,
     "start_time": "2021-06-20T10:36:15.728417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm thinking that the world is soooo unfair......</td>\n",
       "      <td>thinking world soooo unfair sure think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545098</th>\n",
       "      <td>0</td>\n",
       "      <td>oh tasty twist.. you tasted soo good. but i do...</td>\n",
       "      <td>tasty twist tasted good appreciate stomach ache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425195</th>\n",
       "      <td>0</td>\n",
       "      <td>@neilfairmont And of course I had to miss it</td>\n",
       "      <td>neilfairmont course miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267494</th>\n",
       "      <td>0</td>\n",
       "      <td>weekend is now over  have bad sunburn on my ar...</td>\n",
       "      <td>eekend sunburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168949</th>\n",
       "      <td>1</td>\n",
       "      <td>i reeaally need to get out of town... how abou...</td>\n",
       "      <td>reeaally need town paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet  \\\n",
       "24389            0  I'm thinking that the world is soooo unfair......   \n",
       "545098           0  oh tasty twist.. you tasted soo good. but i do...   \n",
       "425195           0      @neilfairmont And of course I had to miss it    \n",
       "267494           0  weekend is now over  have bad sunburn on my ar...   \n",
       "1168949          1  i reeaally need to get out of town... how abou...   \n",
       "\n",
       "                                        processed_tweets  \n",
       "24389             thinking world soooo unfair sure think  \n",
       "545098   tasty twist tasted good appreciate stomach ache  \n",
       "425195                          neilfairmont course miss  \n",
       "267494                                    eekend sunburn  \n",
       "1168949                         reeaally need town paris  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing shortwords\n",
    "tweets['processed_tweets']=tweets['processed_tweets'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b221959",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebf98d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.prior = {}\n",
    "        self.likelihood = {}\n",
    "        self.V = set()\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = re.sub(r'\\W+', ' ', text.lower())\n",
    "        return text.split()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        class_word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        class_counts = defaultdict(int)\n",
    "        doc_counts = defaultdict(int)\n",
    "\n",
    "        for text, label in zip(X, y):\n",
    "            words = set(self.preprocess(text))\n",
    "            for word in words:\n",
    "                class_word_counts[label][word] += 1\n",
    "                self.V.add(word)\n",
    "            class_counts[label] += 1\n",
    "            doc_counts[label] += 1\n",
    "\n",
    "        for label in class_counts:\n",
    "            self.prior[label] = doc_counts[label] / len(X)\n",
    "            total_count = sum(class_word_counts[label].values())\n",
    "            for word in self.V:\n",
    "                self.likelihood[(label, word)] = class_word_counts[label][word] / total_count\n",
    "                \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "            words = self.preprocess(text)\n",
    "            class_scores = {label: self.prior[label] for label in self.prior}\n",
    "\n",
    "            for word in words:\n",
    "                if word in self.V:\n",
    "                    for label in class_scores:\n",
    "                        # If the word has not been seen in the training set for this class, its probability is zero\n",
    "                        class_scores[label] *= self.likelihood.get((label, word), 0)\n",
    "\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c410c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = tweets.sample(frac=0.8, random_state=1)\n",
    "test_data = tweets.drop(train_data.index)\n",
    "\n",
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data['tweet'].tolist(), train_data['sentiment'].tolist())\n",
    "\n",
    "predictions = classifier.predict(test_data['tweet'].tolist())\n",
    "\n",
    "accuracy = sum(test_data['sentiment'] == predictions) / len(test_data)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "146cb090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "TP: 13594, TN: 15554, FP: 4500, FN: 6352\n",
      "Precision: 0.7512987730739472\n",
      "Recall: 0.681540158427755\n",
      "F1 Score: 0.71472134595163\n"
     ]
    }
   ],
   "source": [
    "def calculate_confusion_matrix(true_labels, predictions):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for true, pred in zip(true_labels, predictions):\n",
    "        if true == pred == 1:\n",
    "            TP += 1\n",
    "        elif true == pred == 0:\n",
    "            TN += 1\n",
    "        elif true == 0 and pred == 1:\n",
    "            FP += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            FN += 1\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def calculate_f1_score(TP, TN, FP, FN):\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    return f1\n",
    "\n",
    "def calculate_precision_recall(TP, FP, FN):\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    return precision, recall\n",
    "\n",
    "test_labels = test_data['sentiment'].tolist()\n",
    "\n",
    "TP, TN, FP, FN = calculate_confusion_matrix(test_labels, predictions)\n",
    "print(f\"Confusion Matrix:\\nTP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "\n",
    "precision, recall = calculate_precision_recall(TP, FP, FN)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1 = calculate_f1_score(TP, TN, FP, FN)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 108.829932,
   "end_time": "2021-06-20T10:36:26.474401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-20T10:34:37.644469",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
